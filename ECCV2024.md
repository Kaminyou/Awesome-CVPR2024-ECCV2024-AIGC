# Awesome-ECCV2024-AIGC[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A Collection of Papers and Codes for ECCV2024 AIGC

**整理汇总下今年ECCV AIGC相关的论文和代码，具体如下。**

**欢迎star，fork和PR~**

**Please feel free to star, fork or PR if helpful~**

# **参考或转载请注明出处**

ECCV2024官网：https://eccv.ecva.net/

ECCV接收论文列表：https://cvpr.thecvf.com/Conferences/2024/AcceptedPapers

ECCV完整论文库：https://openaccess.thecvf.com/CVPR2024

开会时间：2024年9月29日-10月4日

论文接收公布时间：2024年

**【Contents】**

- [1.图像生成(Image Generation/Image Synthesis)](#1.图像生成)
- [2.图像编辑（Image Editing)](#2.图像编辑)
- [3.视频生成(Video Generation/Image Synthesis)](#3.视频生成)
- [4.视频编辑(Video Editing)](#4.视频编辑)
- [5.3D生成(3D Generation/3D Synthesis)](#5.3D生成)
- [6.3D编辑(3D Editing)](#6.3D编辑)
- [7.多模态大语言模型(Multi-Modal Large Language Model)](#7.大语言模型)
- [8.其他多任务(Others)](#8.其他)

<a name="1.图像生成"></a>

# 1.图像生成(Image Generation/Image Synthesis)

### Accelerating Diffusion Sampling with Optimized Time Steps

- Paper: https://arxiv.org/abs/2402.17376
- Code: https://github.com/scxue/DM-NonUniform


  

<a name="2.图像编辑"></a>

# 2.图像编辑(Image Editing)

### BrushNet: A Plug-and-Play Image Inpainting Model with Decomposed Dual-Branch Diffusion

- Paper: https://arxiv.org/abs/2403.06976
- Code: https://github.com/TencentARC/BrushNet




<a name="3.视频生成"></a>

# 3.视频生成(Video Generation/Video Synthesis)

### Audio-Synchronized Visual Animation

- Paper: https://arxiv.org/abs/2403.05659
- Code: https://github.com/lzhangbj/ASVA
  
### EDTalk: Efficient Disentanglement for Emotional Talking Head Synthesis

- Paper: https://arxiv.org/abs/2404.01647
- Code: https://github.com/tanshuai0219/EDTalk
  
### MOFA-Video: Controllable Image Animation via Generative Motion Field Adaptions in Frozen Image-to-Video Diffusion Model

- Paper: https://arxiv.org/abs/2405.20222
- Code: https://github.com/MyNiuuu/MOFA-Video
  


  
<a name="4.视频编辑"></a>

# 4.视频编辑(Video Editing)





<a name="5.3D生成"></a>

# 5.3D生成(3D Generation/3D Synthesis)

### ParCo: Part-Coordinating Text-to-Motion Synthesis

- Paper: https://arxiv.org/abs/2403.18512
- Code: https://github.com/qrzou/ParCo




<a name="6.3D编辑"></a>

# 6.3D编辑(3D Editing)






<a name="7.大语言模型"></a>

# 7.多模态大语言模型(Multi-Modal Large Language Models)

### GiT: Towards Generalist Vision Transformer through Universal Language Interface

- Paper: https://arxiv.org/abs/2403.09394
- Code: https://github.com/Haiyang-W/GiT


  

<a name="8.其他"></a>

# 8.其他任务(Others)





<font color=red size=5>持续更新~</font>

# 参考


# 相关整理

- [Awesome-CVPR2024-AIGC](https://github.com/Kobaayyy/Awesome-CVPR2024-AIGC/blob/main/CVPR2024.md)
- [Awesome-AIGC-Research-Groups](https://github.com/Kobaayyy/Awesome-AIGC-Research-Groups)
- [Awesome-Low-Level-Vision-Research-Groups](https://github.com/Kobaayyy/Awesome-Low-Level-Vision-Research-Groups)
- [Awesome-CVPR2024-CVPR2021-CVPR2020-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-CVPR2024-CVPR2021-CVPR2020-Low-Level-Vision)
- [Awesome-ECCV2020-Low-Level-Vision](https://github.com/Kobaayyy/Awesome-ECCV2020-Low-Level-Vision)
